import cv2
import os
import winsound  # Import the winsound module for sound notification

# Print the current working directory to ensure the script is running in the correct location
print("Current Working Directory:", os.getcwd())

# Load Haar Cascades for face and eye detection
face_cascade_path = 'haarcascade_frontalface_default.xml'
eye_cascade_path = 'haarcascade_eye.xml'

face_cascade = cv2.CascadeClassifier(face_cascade_path)
eye_cascade = cv2.CascadeClassifier(eye_cascade_path)

# Check if the cascades were loaded correctly
if face_cascade.empty():
    print(f"Failed to load face cascade from {face_cascade_path}")
if eye_cascade.empty():
    print(f"Failed to load eye cascade from {eye_cascade_path}")

# Constants for drowsiness detection
EYE_AR_THRESH = 0.93  # Adjusted threshold
EYE_AR_CONSEC_FRAMES = 8  # Adjusted frames for alert
COUNTER = 0

# Function to compute Eye Aspect Ratio (EAR)
def eye_aspect_ratio(eye):
    A = cv2.norm(eye[1] - eye[5])
    B = cv2.norm(eye[2] - eye[4])
    C = cv2.norm(eye[0] - eye[3])
    ear = (A + B) / (2.0 * C)
    return ear

# Start video capture
cap = cv2.VideoCapture(0)

while True:
    ret, frame = cap.read()
    if not ret:
        print("Failed to grab frame")
        break

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    gray = cv2.GaussianBlur(gray, (5, 5), 0)  # Apply GaussianBlur to reduce noise
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=3, minSize=(20, 20))

    if len(faces) == 0:
        print("No faces detected")

    for (x, y, w, h) in faces:
        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)  # Draw a rectangle around the face
        roi_gray = gray[y:y + h, x:x + w]
        roi_color = frame[y:y + h, x:x + w]

        eyes = eye_cascade.detectMultiScale(roi_gray, scaleFactor=1.1, minNeighbors=3, minSize=(30, 30))
        eye_aspect_ratios = []

        for (ex, ey, ew, eh) in eyes:
            cv2.rectangle(roi_color, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)
            eye = roi_gray[ey:ey + eh, ex:ex + ew]
            eye_aspect_ratios.append(eye_aspect_ratio(eye))

        if eye_aspect_ratios:
            avg_ear = sum(eye_aspect_ratios) / len(eye_aspect_ratios)
            print(f"EAR: {avg_ear:.2f}")  # Print the EAR for debugging

            if avg_ear < EYE_AR_THRESH:
                COUNTER += 1
                if COUNTER >= EYE_AR_CONSEC_FRAMES:
                    cv2.putText(frame, "DROWSINESS ALERT!", (10, 30),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                    
                    # Play an alert sound
                    winsound.Beep(1000, 500)  # Frequency of 1000 Hz for 500 milliseconds

            else:
                COUNTER = 0

            cv2.putText(frame, "EAR: {:.2f}".format(avg_ear), (300, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

    cv2.imshow('Face Detection', frame)  # Show the frame

    key = cv2.waitKey(1) & 0xFF
    if key == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
